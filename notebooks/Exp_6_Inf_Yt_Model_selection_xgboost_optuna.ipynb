{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_jaf9z6mQmu"
   },
   "source": [
    "###### till Exp_4 have conducted the FE & going ahead with model selection with hp tunning using bayesian optimization.\n",
    "-- XGboost , LightGBM , RF, LOR , SVM , NB , KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMd4fx9unTP1"
   },
   "source": [
    "###### 7 diff files for 7 diff models since in order to avoid the sequential running take more time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XqWPHCrP44Vr"
   },
   "source": [
    "## TRYING XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcC5XaX6nSTa",
    "outputId": "7e60133d-10a4-419a-ed73-96b0c08fef38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-2.18.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.35.64-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting awscli\n",
      "  Downloading awscli-1.36.5-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
      "Collecting mlflow-skinny==2.18.0 (from mlflow)\n",
      "  Downloading mlflow_skinny-2.18.0-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.0.3)\n",
      "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting graphene<4 (from mlflow)\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.2)\n",
      "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.2)\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.36)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
      "Collecting gunicorn<24 (from mlflow)\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.0)\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.18.0->mlflow)\n",
      "  Downloading databricks_sdk-0.38.0-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (1.28.1)\n",
      "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (4.25.5)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.18.0->mlflow) (0.5.2)\n",
      "Collecting botocore<1.36.0,>=1.35.64 (from boto3)\n",
      "  Downloading botocore-1.35.64-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Downloading s3transfer-0.10.3-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli)\n",
      "  Downloading docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.64->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.64->boto3) (2.2.3)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.6)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
      "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (2.27.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.18.0->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b1 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (0.49b1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.64->boto3) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.18.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.18.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.18.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.18.0->mlflow) (0.4.1)\n",
      "Downloading mlflow-2.18.0-py3-none-any.whl (27.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mlflow_skinny-2.18.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.35.64-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading awscli-1.36.5-py3-none-any.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.35.64-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Downloading s3transfer-0.10.3-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m82.6/82.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading databricks_sdk-0.38.0-py3-none-any.whl (575 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m575.1/575.1 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rsa, Mako, jmespath, gunicorn, graphql-core, docutils, colorlog, colorama, graphql-relay, docker, botocore, alembic, s3transfer, optuna, graphene, databricks-sdk, boto3, awscli, mlflow-skinny, mlflow\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.9\n",
      "    Uninstalling rsa-4.9:\n",
      "      Successfully uninstalled rsa-4.9\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.21.2\n",
      "    Uninstalling docutils-0.21.2:\n",
      "      Successfully uninstalled docutils-0.21.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sphinx 8.1.3 requires docutils<0.22,>=0.20, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.6 alembic-1.14.0 awscli-1.36.5 boto3-1.35.64 botocore-1.35.64 colorama-0.4.6 colorlog-6.9.0 databricks-sdk-0.38.0 docker-7.1.0 docutils-0.16 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 jmespath-1.0.1 mlflow-2.18.0 mlflow-skinny-2.18.0 optuna-4.1.0 rsa-4.7.2 s3transfer-0.10.3\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow boto3 awscli optuna xgboost lightgbm imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0pZlqh1mNoZ",
    "outputId": "6b4e43a7-0db2-4f71-f68d-f9d9a404a748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Access Key ID [None]: AKIA2L2SHHQ2FY4SIFJT\n",
      "AWS Secret Access Key [None]: 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\n",
      "Default region name [None]: \n",
      "Default output format [None]: \n"
     ]
    }
   ],
   "source": [
    "!aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m9AvBjd_oLb4"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "# setup mlflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://ec2-35-174-3-91.compute-1.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YfSeitq3oMcE",
    "outputId": "e6560842-39ad-45d4-c6e5-b5935a0a0840"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://interview-mlflow-bucket/851239149715883194', creation_time=1732038163076, experiment_id='851239149715883194', last_update_time=1732038163076, lifecycle_stage='active', name='EXP 5 - ML Algo with HP tuning', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set/create an experiment\n",
    "mlflow.set_experiment(\"EXP 5 - ML Algo with HP tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HiVV9lOoqDe",
    "outputId": "bd2c3d8d-d8b7-44dd-d99e-19f35580c95a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NooRjxJoqEpB",
    "outputId": "e7a84356-c19f-439b-db1a-f1a2fe25d79a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36750, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/reddit_preprocessed.csv').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8e8ed1cqIg2",
    "outputId": "72f7a4d5-df7c-4643-b6dc-b55ca1f8b78f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-19 18:01:07,440] A new study created in memory with name: no-name-469af68c-5c83-417c-9e9e-a209379a980a\n",
      "[I 2024-11-19 18:02:02,111] Trial 0 finished with value: 0.8095071040168391 and parameters: {'n_estimators': 240, 'learning_rate': 0.017460205251243078, 'max_depth': 6}. Best is trial 0 with value: 0.8095071040168391.\n",
      "[I 2024-11-19 18:02:45,482] Trial 1 finished with value: 0.6812839852657429 and parameters: {'n_estimators': 211, 'learning_rate': 0.00046435290314741126, 'max_depth': 5}. Best is trial 0 with value: 0.8095071040168391.\n",
      "[I 2024-11-19 18:03:24,801] Trial 2 finished with value: 0.6249780740221014 and parameters: {'n_estimators': 283, 'learning_rate': 0.00016686784462695427, 'max_depth': 4}. Best is trial 0 with value: 0.8095071040168391.\n",
      "[I 2024-11-19 18:03:46,400] Trial 3 finished with value: 0.7828451148921242 and parameters: {'n_estimators': 62, 'learning_rate': 0.029144967552935264, 'max_depth': 7}. Best is trial 0 with value: 0.8095071040168391.\n",
      "[I 2024-11-19 18:03:59,150] Trial 4 finished with value: 0.8251184002806525 and parameters: {'n_estimators': 78, 'learning_rate': 0.07698326489534062, 'max_depth': 5}. Best is trial 4 with value: 0.8251184002806525.\n",
      "[I 2024-11-19 18:04:12,723] Trial 5 finished with value: 0.6498859849149272 and parameters: {'n_estimators': 153, 'learning_rate': 0.002795813330968205, 'max_depth': 3}. Best is trial 4 with value: 0.8251184002806525.\n",
      "[I 2024-11-19 18:04:38,853] Trial 6 finished with value: 0.8293281880371864 and parameters: {'n_estimators': 95, 'learning_rate': 0.05117123380698589, 'max_depth': 7}. Best is trial 6 with value: 0.8293281880371864.\n",
      "[I 2024-11-19 18:05:18,190] Trial 7 finished with value: 0.7249605332397825 and parameters: {'n_estimators': 144, 'learning_rate': 0.001731924483751553, 'max_depth': 6}. Best is trial 6 with value: 0.8293281880371864.\n",
      "[I 2024-11-19 18:06:38,389] Trial 8 finished with value: 0.715839326433959 and parameters: {'n_estimators': 244, 'learning_rate': 0.0009413438738481213, 'max_depth': 7}. Best is trial 6 with value: 0.8293281880371864.\n",
      "[I 2024-11-19 18:07:18,700] Trial 9 finished with value: 0.6244518505525346 and parameters: {'n_estimators': 289, 'learning_rate': 0.00035895281248373405, 'max_depth': 4}. Best is trial 6 with value: 0.8293281880371864.\n",
      "[I 2024-11-19 18:08:28,135] Trial 10 finished with value: 0.7835467461848798 and parameters: {'n_estimators': 116, 'learning_rate': 0.009418189735389512, 'max_depth': 10}. Best is trial 6 with value: 0.8293281880371864.\n",
      "[I 2024-11-19 18:08:50,428] Trial 11 finished with value: 0.8328363445009648 and parameters: {'n_estimators': 54, 'learning_rate': 0.07631802613075643, 'max_depth': 9}. Best is trial 11 with value: 0.8328363445009648.\n",
      "[I 2024-11-19 18:09:23,156] Trial 12 finished with value: 0.8537098754604455 and parameters: {'n_estimators': 96, 'learning_rate': 0.06545396956493793, 'max_depth': 9}. Best is trial 12 with value: 0.8537098754604455.\n",
      "[I 2024-11-19 18:09:56,149] Trial 13 finished with value: 0.7746009472022453 and parameters: {'n_estimators': 54, 'learning_rate': 0.007988892192419791, 'max_depth': 10}. Best is trial 12 with value: 0.8537098754604455.\n",
      "[I 2024-11-19 18:10:27,949] Trial 14 finished with value: 0.8815997193474829 and parameters: {'n_estimators': 112, 'learning_rate': 0.09754418475178254, 'max_depth': 9}. Best is trial 14 with value: 0.8815997193474829.\n",
      "[I 2024-11-19 18:11:18,534] Trial 15 finished with value: 0.8254692159270304 and parameters: {'n_estimators': 121, 'learning_rate': 0.02956469868890669, 'max_depth': 9}. Best is trial 14 with value: 0.8815997193474829.\n",
      "[I 2024-11-19 18:12:33,797] Trial 16 finished with value: 0.7870549026486582 and parameters: {'n_estimators': 180, 'learning_rate': 0.009424047087389866, 'max_depth': 8}. Best is trial 14 with value: 0.8815997193474829.\n",
      "[I 2024-11-19 18:13:03,485] Trial 17 finished with value: 0.8735309594807928 and parameters: {'n_estimators': 100, 'learning_rate': 0.09709975317716582, 'max_depth': 9}. Best is trial 14 with value: 0.8815997193474829.\n",
      "[I 2024-11-19 18:14:04,395] Trial 18 finished with value: 0.8289773723908086 and parameters: {'n_estimators': 180, 'learning_rate': 0.023949053347854993, 'max_depth': 8}. Best is trial 14 with value: 0.8815997193474829.\n",
      "[I 2024-11-19 18:15:10,070] Trial 19 finished with value: 0.7593404665848097 and parameters: {'n_estimators': 150, 'learning_rate': 0.004339728064379418, 'max_depth': 8}. Best is trial 14 with value: 0.8815997193474829.\n",
      "[I 2024-11-19 18:15:47,693] Trial 20 finished with value: 0.8868619540431503 and parameters: {'n_estimators': 116, 'learning_rate': 0.09776995501893956, 'max_depth': 10}. Best is trial 20 with value: 0.8868619540431503.\n",
      "[I 2024-11-19 18:16:26,223] Trial 21 finished with value: 0.8880898088054727 and parameters: {'n_estimators': 119, 'learning_rate': 0.0971304208805712, 'max_depth': 10}. Best is trial 21 with value: 0.8880898088054727.\n",
      "[I 2024-11-19 18:17:19,981] Trial 22 finished with value: 0.8473951938256447 and parameters: {'n_estimators': 128, 'learning_rate': 0.03929606711883277, 'max_depth': 10}. Best is trial 21 with value: 0.8880898088054727.\n",
      "[I 2024-11-19 18:18:42,929] Trial 23 finished with value: 0.8231889142255745 and parameters: {'n_estimators': 169, 'learning_rate': 0.01755744421519925, 'max_depth': 10}. Best is trial 21 with value: 0.8880898088054727.\n",
      "[I 2024-11-19 18:19:23,569] Trial 24 finished with value: 0.8912471496228732 and parameters: {'n_estimators': 130, 'learning_rate': 0.09881760058883167, 'max_depth': 10}. Best is trial 24 with value: 0.8912471496228732.\n",
      "[I 2024-11-19 18:20:15,184] Trial 25 finished with value: 0.8659884230836695 and parameters: {'n_estimators': 136, 'learning_rate': 0.05155769572205888, 'max_depth': 10}. Best is trial 24 with value: 0.8912471496228732.\n",
      "[I 2024-11-19 18:20:50,507] Trial 26 finished with value: 0.781091036660235 and parameters: {'n_estimators': 81, 'learning_rate': 0.017134469725228783, 'max_depth': 8}. Best is trial 24 with value: 0.8912471496228732.\n",
      "[I 2024-11-19 18:22:01,195] Trial 27 finished with value: 0.873180143834415 and parameters: {'n_estimators': 205, 'learning_rate': 0.04263099493267941, 'max_depth': 10}. Best is trial 24 with value: 0.8912471496228732.\n",
      "[I 2024-11-19 18:23:30,577] Trial 28 finished with value: 0.7738993159094896 and parameters: {'n_estimators': 170, 'learning_rate': 0.005736596405234988, 'max_depth': 9}. Best is trial 24 with value: 0.8912471496228732.\n",
      "[I 2024-11-19 18:24:16,785] Trial 29 finished with value: 0.7830205227153131 and parameters: {'n_estimators': 75, 'learning_rate': 0.014259663732484485, 'max_depth': 10}. Best is trial 24 with value: 0.8912471496228732.\n",
      "2024/11/19 18:25:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run XGBOOST_SMOTE_TFIDF_Trigrams at: http://ec2-35-174-3-91.compute-1.amazonaws.com:5000/#/experiments/851239149715883194/runs/9720166b58c0490b8f7e2cb75057b157\n",
      "ğŸ§ª View experiment at: http://ec2-35-174-3-91.compute-1.amazonaws.com:5000/#/experiments/851239149715883194\n"
     ]
    }
   ],
   "source": [
    "# S1 :- reset the categories since Xgboost doesn't consider the -1 as a category\n",
    "df['category'] = df['category'].map({-1:2,0:0,1:1})\n",
    "\n",
    "# S2 :- remove the category where ever nan\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# S3 :- set trigram & maxfeature\n",
    "ngram_range = (1,3)\n",
    "max_features = 10000 # set 1000 for tfidf vec\n",
    "\n",
    "# S4 :- split the data to avoid data leakage before resampling & vectorization\n",
    "X_train, X_test ,y_train , y_test = train_test_split(df['clean_comment'],df['category'],test_size=0.2,random_state=42,stratify=df['category'])\n",
    "\n",
    "# vectorize using tfidf on train data only\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range,max_features=max_features)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# sampling\n",
    "smote = SMOTE(random_state = 42)\n",
    "X_train_vec, y_train = smote.fit_resample(X_train_vec,y_train)\n",
    "\n",
    "# MLFlow Func log metrics,model,artifacts & others\n",
    "\n",
    "def log_mlflow(model_name,model,X_train,X_test,y_train,y_test):\n",
    "  with mlflow.start_run():\n",
    "\n",
    "    # log model type\n",
    "    mlflow.set_tag(\"mlflow.runName\",f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
    "    mlflow.set_tag(\"experiment_type\",\"algorithm comparision\")\n",
    "\n",
    "    # log algo name as a param\n",
    "    mlflow.log_param(\"algo_name\",model_name)\n",
    "\n",
    "    # train model\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # log accuracy\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    mlflow.log_param(\"accuracy\",accuracy)\n",
    "\n",
    "    # log classification report\n",
    "\n",
    "    classification_rep = classification_report(y_test,y_pred,output_dict=True)\n",
    "    for label , metrics in classification_rep.items():\n",
    "      if isinstance(metrics,dict):\n",
    "        for metric,value in metrics.items():\n",
    "          mlflow.log_metric(f\"{label}_{metric}\",value)\n",
    "\n",
    "    # log model\n",
    "    mlflow.sklearn.log_model(model,f\"{model_name}_model\")\n",
    "\n",
    "\n",
    "# HP tune OPTUNA obj func for XGBOOST\n",
    "\n",
    "def objective_xgboost(trial):\n",
    "  n_estimators = trial.suggest_int('n_estimators',50,300)\n",
    "  learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1,log=True)\n",
    "  max_depth = trial.suggest_int('max_depth',3,10)\n",
    "\n",
    "  model = XGBClassifier(n_estimators=n_estimators,learning_rate=learning_rate,max_depth=max_depth,random_state=42)\n",
    "  return accuracy_score(y_test,model.fit(X_train_vec,y_train).predict(X_test_vec))\n",
    "\n",
    "\n",
    "# Step 7 Run optuna for xgboost & log the best model only\n",
    "def run_optuna_experiment():\n",
    "  study = optuna.create_study(direction = \"maximize\")\n",
    "  study.optimize(objective_xgboost,n_trials=30)\n",
    "\n",
    "  # get the best params & log the best model only\n",
    "  best_params = study.best_params\n",
    "  best_model = XGBClassifier(n_estimators=best_params['n_estimators'],learning_rate=best_params['learning_rate'],max_depth=best_params['max_depth'],random_state=42)\n",
    "\n",
    "  # log the best model & pass the name as \"xgboost\"\n",
    "  log_mlflow(\"XGBOOST\",best_model,X_train_vec,X_test_vec,y_train,y_test)\n",
    "\n",
    "# run the experiment for xgboost\n",
    "run_optuna_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1i4xrzVVqI7V"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7FhQDNBIqJTU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G93rrFL3qJtD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86izyGJIqKG0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
